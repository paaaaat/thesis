@misc{statista2025,
  author = {{Statista}},
  title  = {Amount of Data Created Worldwide 2010-2025},
  year   = {2025},
  url    = {https://www.statista.com/statistics/871513/worldwide-data-created/}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Mark and Mishra, Gaurav and Roberts, Adam and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{scao2022bloom,
  title   = {BLOOM: A 176B-Parameter Open-Access Multilingual Language Model},
  author  = {Scao, Teven Le and Fan, Angela and Akiki, Christopher and others},
  journal = {arXiv preprint arXiv:2211.05100},
  year    = {2022}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and others},
  booktitle={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{mcculloch1943logical,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  journal = {The Bulletin of Mathematical Biophysics},
  volume = {5},
  number = {4},
  pages = {115--133},
  year = {1943},
  publisher = {Springer}
}

@misc{lewis2020retrieval,
  title         = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
  author        = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
  year          = {2021},
  eprint        = {2005.11401},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.11401}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{liu2024understanding,
  title   = {Understanding LLMs: A Comprehensive Overview from Training to Inference},
  author  = {Liu, Yixin and Zhang, Haoyu and Zhang, Zhanpeng and others},
  journal = {arXiv preprint arXiv:2401.02038},
  year    = {2024}
}

@misc{hu2021lora,
  title         = {LoRA: Low-Rank Adaptation of Large Language Models},
  author        = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  year          = {2021},
  eprint        = {2106.09685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2106.09685}
}


@misc{huggingfacecourse,
  author = {Hugging Face},
  title = {The Hugging Face Course, 2022},
  howpublished = "\url{https://huggingface.co/course}",
  year = {2022},
  note = "[Online; accessed <today>]"
}


@article{rumelhart1986learning,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Nature},
  volume={323},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@inproceedings{lecun1998gradient,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  booktitle={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998}
}


@article{rosenblatt1958perceptron,
  title   = {The Perceptron: A probabilistic model for information storage and organization in the brain},
  author  = {Rosenblatt, Frank},
  journal = {Psychological Review},
  volume  = {65},
  number  = {6},
  pages   = {386--408},
  year    = {1958}
}

@book{minsky1969perceptrons,
  title     = {Perceptrons},
  author    = {Minsky, Marvin and Papert, Seymour},
  publisher = {MIT Press},
  year      = {1969}
}

@book{goodfellow2016deep,
  title     = {Deep Learning},
  author    = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  publisher = {MIT Press},
  year      = {2016}
}

@inproceedings{krizhevsky2012imagenet,
  title     = {ImageNet Classification with Deep Convolutional Neural Networks},
  author    = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2012}
}

@article{hochreiter1997long,
  title     = {Long short-term memory},
  author    = {Hochreiter, Sepp and Schmidhuber, Jürgen},
  journal   = {Neural Computation},
  volume    = {9},
  number    = {8},
  pages     = {1735--1780},
  year      = {1997},
  publisher = {MIT Press}
}

@inproceedings{cho2014learning,
  title     = {Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation},
  author    = {Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and others},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2014}
}

@inproceedings{mikolov2013distributed,
  title     = {Efficient Estimation of Word Representations in Vector Space},
  author    = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  booktitle = {Proceedings of the International Conference on Learning Representations (ICLR)},
  year      = {2013}
}

@inproceedings{pennington2014glove,
  title     = {GloVe: Global Vectors for Word Representation},
  author    = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2014}
}

@inproceedings{peters2018deep,
  title     = {Deep Contextualized Word Representations},
  author    = {Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and others},
  booktitle = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year      = {2018}
}

@inproceedings{devlin2019bert,
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year      = {2019}
}

@article{liu2023promptsurvey,
  title   = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  author  = {Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and others},
  journal = {ACM Computing Surveys},
  volume  = {55},
  number  = {9},
  year    = {2023}
}


@misc{dettmers2022int8,
  title         = {LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale},
  author        = {Tim Dettmers and Mike Lewis and Younes Belkada and Luke Zettlemoyer},
  year          = {2022},
  eprint        = {2208.07339},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2208.07339}
}


@article{hoffmann2022trainingcomputeoptimal,
  title   = {Training Compute-Optimal Large Language Models},
  author  = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and others},
  journal = {arXiv preprint arXiv:2203.15556},
  year    = {2022}
}

@article{ji2023surveyhallucination,
  title   = {A Survey of Hallucination in Large Language Models},
  author  = {Ji, Zhijing and Lee, Zheng-Xin and Sun, Chenguang and others},
  journal = {arXiv preprint arXiv:2304.03240},
  year    = {2023}
}

@inproceedings{bender2021parrots,
  title     = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author    = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (FAccT)},
  year      = {2021}
}

@article{weidinger2022ethical,
  title   = {Ethical and Social Risks of Harm from Language Models},
  author  = {Weidinger, Laura and Mellor, Joe and Rauh, Lisa and others},
  journal = {arXiv preprint arXiv:2112.04359},
  year    = {2022}
}


@online{uspenskyi2025,
  author  = {Serhii Uspenskyi},
  title   = {Large Language Model Statistics And Numbers (2025)},
  year    = 2025,
  url     = {https://springsapps.com/knowledge/large-language-model-statistics-and-numbers-2024}
}


@misc{raffel2020t5,
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author  = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
  journal = {arXiv preprint arXiv:1910.10683},
  year    = {2020}
}


@misc{minaee2024largelanguagemodelssurvey,
  title         = {Large Language Models: A Survey},
  author        = {Minaee, Shervin and Mikolov, Tomas and Nikzad, Narjes and Chenaghlu, Meysam and Socher, Richard and Amatriain, Xavier and Gao, Jianfeng},
  year          = {2024},
  eprint        = {2402.06196},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.06196}
}

@article{kaplan2020scaling,
  author  = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  title   = {Scaling Laws for Neural Language Models},
  journal = {arXiv preprint arXiv:2001.08361},
  year    = {2020},
  month   = {1},
  url     = {https://arxiv.org/abs/2001.08361}
}


@misc{zhang2024sprigimprovinglargelanguage,
  title         = {SPRIG: Improving Large Language Model Performance by System Prompt Optimization},
  author        = {Lechen Zhang and Tolga Ergen and Lajanugen Logeswaran and Moontae Lee and David Jurgens},
  year          = {2024},
  eprint        = {2410.14826},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.14826}
}


@misc{rajaraman2024theorytokenizationllms,
  title         = {Toward a Theory of Tokenization in LLMs},
  author        = {Nived Rajaraman and Jiantao Jiao and Kannan Ramchandran},
  year          = {2024},
  eprint        = {2404.08335},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2404.08335}
}


@misc{openai2025textgeneration,
  author       = {{OpenAI}},
  title        = {Text Generation},
  year         = {2025},
  howpublished = {\url{https://platform.openai.com/docs/guides/text-generation}}
}


@inproceedings{sennrich2016neural,
  title        = {Neural Machine Translation of Rare Words with Subword Units},
  author       = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  booktitle    = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages        = {1715--1725},
  year         = {2016},
  organization = {Association for Computational Linguistics}
}


@article{radford2018improving,
  title   = {Improving Language Understanding by Generative Pre-Training},
  author  = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  journal = {OpenAI Technical Report},
  year    = {2018}
}


@misc{sahoo2024systematicsurveypromptengineering,
  title         = {A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
  author        = {Pranab Sahoo and Ayush Kumar Singh and Sriparna Saha and Vinija Jain and Samrat Mondal and Aman Chadha},
  year          = {2024},
  eprint        = {2402.07927},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2402.07927}
}


@misc{reynolds2021promptprogramminglargelanguage,
  title         = {Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm},
  author        = {Laria Reynolds and Kyle McDonell},
  year          = {2021},
  eprint        = {2102.07350},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2102.07350}
}


@misc{w3schools2025,
  author = {{W3Schools}},
  title  = {ChatGPT-3.5 Roles},
  year   = {2025},
  url    = {https://www.w3schools.com/gen_ai/chatgpt-3-5/chatgpt-3-5_roles.php}
}


@misc{wei2023chainofthought,
  title         = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author        = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year          = {2023},
  eprint        = {2201.11903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2201.11903}
}


@misc{agents2025,
  author       = {Wiesinger, Julia and Marlow, Patrick and Vuskovic, Vladimir},
  title        = {Agents},
  year         = {2024},
  howpublished = {Kaggle},
  url          = {https://www.kaggle.com/whitepaper-agents}
}


@misc{gyawali2023gpu,
  title         = {Comparative Analysis of CPU and GPU Profiling for Deep Learning Models},
  author        = {Dipesh Gyawali},
  year          = {2023},
  eprint        = {2309.02521},
  archiveprefix = {arXiv},
  primaryclass  = {cs.DC},
  url           = {https://arxiv.org/abs/2309.02521}
}


@misc{colab2025,
  author = {{Google}},
  title  = {{Google Colaboratory}},
  year   = {2025},
  url    = {https://colab.research.google.com/}
}


@misc{nvidia2025,
  author = {{NVIDIA}},
  title  = {{Tesla T4 - NVIDIA Data Center}},
  year   = {2025},
  url    = {https://www.nvidia.com/it-it/data-center/tesla-t4/}
}


@misc{openmeteo,
  title        = {Open-Meteo: Free Weather API},
  howpublished = {\url{https://open-meteo.com/}},
  year         = {2023}
}