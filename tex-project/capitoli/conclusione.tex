This thesis has presented a practical exploration into the integration of alternative techniques to the industry standards of fine-tuning for implementing Large Language Models (LLMs), specifically focusing on developing a context-aware recommender system designed for tourists visiting Verona, Italy. By leveraging the open-source LLaMA 3.1 8B-Instruct model and employing advanced techniques such as 8-bit quantization, Retrieval-Augmented Generation, Prompt Engineering and Agentic AI, this study demonstrates that it is feasible to deploy state-of-the-art conversational AI solutions even under limited computational resources.

Chapter 2 addressed the foundational aspects of neural networks and their evolution, starting with the very first attempt of reproducing the human brain to render machines as learning entities, the \textit{Perceptron}, which layed the foundations for successful machine learning architectures, until highlighting the transformative role of the Transformer architecture, introcing a Multi-Head Attention mechanism which captures the semantic of natural language with all its facets efficiently.

Chapter 3 followed by a thorough exploration of recent advancements in LLMs, including key techniques such as Prompt Engineering, Retrieval-Augmented Generation (RAG), and Agent AI. These elements are fundamentally possible due to demonstrated \textit{few-shot} capabilities of modern LLMs, due to increasing parameter sizes and hardware advancements, and provided the theoretical and practical foundation essential for building domain-specific conversational AI systems.

In the implementation phase (Chapter 4) the thesis focused on a practical use-case: recommending points of interest to tourists in Verona. An 8-bit quantized version of the LLaMA 3.1 8B-Instruct model was selected due to its efficient balance of computational demand and functional capability. The developed VeronaCard Assistant successfully illustrates how carefully structured prompts, combined with dynamically retrieved external data—such as historical tourist attendance records and real-time weather conditions—can significantly enhance the practicality, accuracy, and usefulness of AI-generated recommendations.

Experimental results described in Chapter 5 and user interactions confirmed that the application effectively guided users toward personalized experiences, adapting recommendations based on dynamic variables like attendance patterns and weather forecasts. The assistant showed promising capabilities in generating meaningful, contextually appropriate recommendations. It effectively responded to user inquiries, handled multi-turn conversations gracefully, and incorporated external data sources efficiently. However, several limitations were identified, including occasional inaccuracies in recommendations due to model hallucinations and challenges in maintaining relevance in dynamic scenarios. Additionally, while prompt engineering and role prompting significantly improved context-awareness and user engagement, fine-tuning remains a key strategy to significantly implement useful models, especially regarding nuanced user preferences and specific conversational contexts.

In conclusion, the thesis has provided meaningful insights into leveraging large language models for domain-specific applications, such as tourist engagement and recommendation systems. It demonstrated the practical application of state-of-the-art AI techniques within the tourism sector, effectively bridging theoretical advancements with real-world use cases. The use of Retrieval-Augmented Generation, careful Prompt Engineering and Agentic behavior with limited computational resources highlights the significant potential and practicality of LLM-based recommender systems. As LLM technologies continue to advance, opportunities for further enhancement and broader application will undoubtedly arise, offering ever more engaging, intelligent, and helpful user experiences in tourism and beyond.